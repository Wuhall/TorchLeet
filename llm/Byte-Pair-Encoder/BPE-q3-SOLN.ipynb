{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "081a9dd1",
   "metadata": {},
   "source": [
    "## Problem: Write a Byte Pain Encoder in Python\n",
    "\n",
    "### Problem Statement\n",
    "Implement a **Transformer model** in PyTorch by completing the required sections. The model should consist of an embedding layer, a Transformer encoder, and an output layer for sequence processing and prediction.\n",
    "\n",
    "### Requirements\n",
    "1. **Define the Transformer Model Architecture**:\n",
    "   - **Embedding Layer**:\n",
    "     - Implement a layer to transform input data into a higher-dimensional space.\n",
    "     - Use a `torch.nn.Linear` or `torch.nn.Embedding` layer to create embeddings from the input.\n",
    "   - **Transformer Encoder**:\n",
    "     - Use `torch.nn.TransformerEncoder` or `torch.nn.Transformer` to process sequences with attention.\n",
    "     - Configure parameters such as the number of attention heads and encoder layers.\n",
    "   - **Output Layer**:\n",
    "     - Add a fully connected (linear) layer to reduce the transformer's sequence output into the desired output dimension.\n",
    "\n",
    "2. **Implement the Forward Method**:\n",
    "   - Map the input to the higher-dimensional space using the embedding layer.\n",
    "   - Pass the transformed input through the Transformer encoder.\n",
    "   - Use the output layer to convert the encoded sequence into predictions.\n",
    "\n",
    "### Constraints\n",
    "- Handle input padding correctly for variable-length sequences.\n",
    "- Ensure compatibility with batch processing by correctly shaping input and output tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f09999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge 1: ('l', 'o')\n",
      "Merge 2: ('lo', 'w')\n",
      "Merge 3: ('e', 'r')\n",
      "Merge 4: ('er', '</w>')\n",
      "Merge 5: ('low', '</w>')\n",
      "Merge 6: ('low', 'e')\n",
      "Merge 7: ('lowe', 's')\n",
      "Merge 8: ('lowes', 't')\n",
      "Merge 9: ('lowest', '</w>')\n",
      "Merge 10: ('n', 'e')\n",
      "\n",
      "Final Vocabulary:\n",
      "low</w> : 1\n",
      "lowest</w> : 1\n",
      "ne w er</w> : 1\n",
      "w i d er</w> : 1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "def get_vocab(corpus):\n",
    "    \"\"\"Creates a vocabulary with words split into characters and a special end-of-word token.\"\"\"\n",
    "    vocab = Counter()\n",
    "    for word in corpus:\n",
    "        tokens = list(word) + ['</w>']\n",
    "        vocab[tuple(tokens)] += 1\n",
    "    return vocab\n",
    "\n",
    "def get_stats(vocab):\n",
    "    \"\"\"Counts frequency of adjacent symbol pairs.\"\"\"\n",
    "    pairs = defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        for i in range(len(word) - 1):\n",
    "            pairs[(word[i], word[i + 1])] += freq\n",
    "    return pairs\n",
    "\n",
    "def merge_vocab(pair, vocab):\n",
    "    \"\"\"Merges the most frequent pair into a single symbol.\"\"\"\n",
    "    new_vocab = {}\n",
    "    bigram = ' '.join(pair)\n",
    "    replacement = ''.join(pair)\n",
    "    for word, freq in vocab.items():\n",
    "        word_str = ' '.join(word)\n",
    "        # Replace bigram with merged symbol\n",
    "        new_word_str = word_str.replace(bigram, replacement)\n",
    "        new_vocab[tuple(new_word_str.split())] = freq\n",
    "    return new_vocab\n",
    "\n",
    "def byte_pair_encoding(corpus, num_merges=10):\n",
    "    \"\"\"Performs BPE on a corpus.\"\"\"\n",
    "    vocab = get_vocab(corpus)\n",
    "    merges = []\n",
    "    for _ in range(num_merges):\n",
    "        pairs = get_stats(vocab)\n",
    "        if not pairs:\n",
    "            break\n",
    "        best = max(pairs, key=pairs.get)\n",
    "        vocab = merge_vocab(best, vocab)\n",
    "        merges.append(best)\n",
    "        print(f\"Merge {_ + 1}: {best}\")\n",
    "    return vocab, merges\n",
    "\n",
    "# Example usage\n",
    "corpus = [\"low\", \"lowest\", \"newer\", \"wider\"]\n",
    "final_vocab, merge_operations = byte_pair_encoding(corpus, num_merges=10)\n",
    "\n",
    "print(\"\\nFinal Vocabulary:\")\n",
    "for word in final_vocab:\n",
    "    print(' '.join(word), \":\", final_vocab[word])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4638a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ test_get_vocab passed\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_get_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Run all tests\u001b[39;00m\n\u001b[1;32m     35\u001b[0m test_get_vocab()\n\u001b[0;32m---> 36\u001b[0m \u001b[43mtest_get_\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_get_' is not defined"
     ]
    }
   ],
   "source": [
    "def test_get_vocab():\n",
    "    corpus = [\"test\"]\n",
    "    vocab = get_vocab(corpus)\n",
    "    assert vocab == {('t', 'e', 's', 't', '</w>'): 1}\n",
    "    print(\"✓ test_get_vocab passed\")\n",
    "\n",
    "def test_get_stats():\n",
    "    vocab = {('t', 'e', 's', 't', '</w>'): 1}\n",
    "    stats = get_stats(vocab)\n",
    "    expected = {\n",
    "        ('t', 'e'): 1,\n",
    "        ('e', 's'): 1,\n",
    "        ('s', 't'): 1,\n",
    "        ('t', '</w>'): 1\n",
    "    }\n",
    "    assert stats == expected\n",
    "    print(\"✓ test_get_stats passed\")\n",
    "\n",
    "def test_merge_vocab():\n",
    "    vocab = {('t', 'e', 's', 't', '</w>'): 1}\n",
    "    merged = merge_vocab(('e', 's'), vocab)\n",
    "    expected = {('t', 'es', 't', '</w>'): 1}\n",
    "    assert merged == expected\n",
    "    print(\"✓ test_merge_vocab passed\")\n",
    "\n",
    "def test_bpe_sequence():\n",
    "    corpus = [\"low\", \"lower\", \"newest\", \"widest\"]\n",
    "    final_vocab, merges = byte_pair_encoding(corpus, num_merges=5)\n",
    "    assert isinstance(final_vocab, dict)\n",
    "    assert all(isinstance(pair, tuple) for pair in merges)\n",
    "    assert len(merges) == 5\n",
    "    print(\"✓ test_bpe_sequence passed\")\n",
    "\n",
    "# Run all tests\n",
    "test_get_vocab()\n",
    "test_get_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
